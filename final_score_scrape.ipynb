{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "f8c86f2e-21b1-43c2-850f-ee9334957edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant libraries\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "9b4b9556-79cc-4b5a-82db-5f430cf3c752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2019, 2020]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seasons = list(range(2019,2021))\n",
    "seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "4f0e3967-173a-411e-af55-70d4735a1192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the browser\n",
    "executable_path = {'executable_path':\"C:\\Program Files (x86)\\msedgedriver.exe\"}\n",
    "browser = Browser('edge', **executable_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "a1f60598-3ad4-4739-b321-c32a84e740d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_season_info(soup):\n",
    "    nav = soup.find('div', id='bottom_nav_container')\n",
    "    hrefs = [a[\"href\"] for a in nav.find_all(\"a\")]\n",
    "    season = hrefs[1].split()[0].split('_')[0].split('/')[-1]\n",
    "    return season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c85a829-c1ca-4cd6-b9f7-ade529b32eef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "eaf6ed24-4036-4c8e-9a23-0bf40e0e072f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# games = []\n",
    "\n",
    "# for season in seasons:\n",
    "#     # Visit the website for scraping\n",
    "#     url = f\"https://www.basketball-reference.com/leagues/NBA_{season}_games.html\"\n",
    "#     browser.visit(url)\n",
    "#     time.sleep(1)\n",
    "\n",
    "#     # Create a BeautifulSoup object\n",
    "#     html = browser.html\n",
    "#     soup = BeautifulSoup(html, 'html.parser')\n",
    "#     table = soup.find('div', id='content')\n",
    "\n",
    "#     if table is not None:\n",
    "#         month_filter = table.find('div', class_='filter')\n",
    "#         links = month_filter.find_all(\"a\")\n",
    "#         hrefs = [link.get(\"href\") for link in links]\n",
    "#         standing_pages = [f\"https://www.basketball-reference.com{link}\" for link in hrefs]\n",
    "        \n",
    "#         for page in standing_pages:\n",
    "#             browser.visit(page)\n",
    "#             time.sleep(1)\n",
    "            \n",
    "#             # Create a BeautifulSoup object\n",
    "#             html = browser.html\n",
    "#             soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "#             links = soup.find_all(\"a\")\n",
    "#             hrefs = [link.get(\"href\") for link in links]\n",
    "#             box_scores = [link for link in hrefs if link and \"boxscore\" in link and \".html\" in link]\n",
    "#             box_scores = [f\"https://www.basketball-reference.com{score}\" for score in box_scores]\n",
    "\n",
    "#             base_cols = None\n",
    "#             for box_score in box_scores:\n",
    "#                 browser.visit(box_score)\n",
    "#                 time.sleep(2)\n",
    "#                 html=browser.html\n",
    "#                 soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "#                 score_table = soup.find('table', id='line_score')\n",
    "#                 tbody = score_table.find('tbody')\n",
    "#                 rows = tbody.find_all('tr')\n",
    "\n",
    "#                 line_score = []\n",
    "#                 for row in rows:\n",
    "#                     # Get team name\n",
    "#                     team = row.find('th', class_='center').text\n",
    "#                     columns = row.find_all('td')\n",
    "\n",
    "#                     # Create line score dictionary\n",
    "#                     if(columns !=[]):\n",
    "#                         total = columns[4].text\n",
    "\n",
    "#                     # Create dictionary for dataframe later\n",
    "#                     line_score_dict = { \"team\": team,\n",
    "#                                         \"total\": total\n",
    "#                     }\n",
    "\n",
    "#                     # Add dictionary to array\n",
    "#                     line_score.append(line_score_dict)\n",
    "\n",
    "#                 # Create Data frame\n",
    "#                 score_df = pd.DataFrame(line_score)\n",
    "#                 teams = [score[\"team\"] for score in line_score]\n",
    "\n",
    "#                 summaries = []\n",
    "#                 for team in teams:\n",
    "#                     # Convert html table into pandas dataframe\n",
    "#                     basic = pd.read_html(str(soup), attrs={\"id\": f\"box-{team}-game-basic\"}, index_col=0)[0]\n",
    "#                     advanced = pd.read_html(str(soup), attrs={\"id\": f\"box-{team}-game-advanced\"}, index_col=0)[0]\n",
    "\n",
    "#                     # Convert all columns with number to numeric for dataframes\n",
    "#                     basic = basic.apply(pd.to_numeric, errors=\"coerce\")\n",
    "#                     advanced = advanced.apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "#                     # Remove the row that contains heards within the dataframe\n",
    "#                     advanced = advanced.drop('Reserves')\n",
    "#                     basic = basic.drop('Reserves')\n",
    "\n",
    "#                     # Get headers for basic and advanced stats\n",
    "#                     advanced_columns = []\n",
    "#                     basic_columns = []\n",
    "#                     for i in range(len(advanced.columns)):\n",
    "#                         advanced_columns.append(advanced.columns[i][1])\n",
    "\n",
    "#                     for i in range(len(basic.columns)):\n",
    "#                         basic_columns.append(basic.columns[i][1])\n",
    "\n",
    "#                     advanced.columns = advanced_columns\n",
    "#                     basic.columns = basic_columns\n",
    "\n",
    "#                     # Totals and Maxes\n",
    "#                     totals = pd.concat([basic.iloc[-1, :], advanced.iloc[-1, :]])\n",
    "#                     totals.index = totals.index.str.lower()\n",
    "\n",
    "#                     maxes = pd.concat([basic.iloc[:-1, :].max(), advanced.iloc[:-1, :].max()])\n",
    "#                     maxes.index = maxes.index.str.lower() + \"_max\"\n",
    "\n",
    "#                     summary = pd.concat([totals, maxes])\n",
    "\n",
    "#                     # Create comon columns that are found for all teams\n",
    "#                     if base_cols is None:\n",
    "#                         base_cols = list(summary.index.drop_duplicates(keep=\"first\"))\n",
    "#                         base_cols = [b for b in base_cols if \"bpm\" not in b]\n",
    "\n",
    "#                     summary = summary[base_cols]\n",
    "#                     summaries.append(summary)\n",
    "\n",
    "#                 summary = pd.concat(summaries, axis=1).T\n",
    "#                 game = pd.concat([summary, score_df], axis=1)\n",
    "#                 game[\"home\"] = [0, 1]\n",
    "\n",
    "#                 game_opp = game.iloc[::-1].reset_index()\n",
    "#                 game_opp.columns += \"_opp\"\n",
    "\n",
    "#                 # Merge both hame and away team data together\n",
    "#                 full_game = pd.concat([game, game_opp], axis=1)\n",
    "\n",
    "#                 # Add the season the game was played in\n",
    "#                 full_game[\"season\"] = read_season_info(soup)\n",
    "\n",
    "#                 # Add date to dataframe\n",
    "#                 full_game[\"date\"] = box_score.split('/')[-1][:8]\n",
    "#                 full_game[\"date\"] = pd.to_datetime(full_game[\"date\"], format=\"%Y%m%d\")\n",
    "\n",
    "#                 # Specify who won the game\n",
    "#                 full_game[\"won\"] = full_game[\"total\"] > full_game[\"total_opp\"]\n",
    "\n",
    "#                 games.append(full_game)\n",
    "\n",
    "#                 if len(games) % 100 == 0:\n",
    "#                     print(f\"{len(games)} / {len(box_scores)}\")\n",
    "\n",
    "#                 # time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816e8975-fe51-4360-b9f5-48b89eaa410b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa55353-887a-4af9-9f5e-a04270f9155b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 / 122\n"
     ]
    }
   ],
   "source": [
    "games = []\n",
    "\n",
    "for season in seasons:\n",
    "    # Visit the website for scraping\n",
    "    url = f\"https://www.basketball-reference.com/leagues/NBA_{season}_games.html\"\n",
    "    browser.visit(url)\n",
    "    time.sleep(1)\n",
    "\n",
    "    # Create a BeautifulSoup object\n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    table = soup.find('div', id='content')\n",
    "\n",
    "    if table is not None:\n",
    "        month_filter = table.find('div', class_='filter')\n",
    "        links = month_filter.find_all(\"a\")\n",
    "        hrefs = [link.get(\"href\") for link in links]\n",
    "        standing_pages = [f\"https://www.basketball-reference.com{link}\" for link in hrefs]\n",
    "        \n",
    "        for page in standing_pages:\n",
    "            browser.visit(page)\n",
    "            time.sleep(1)\n",
    "            \n",
    "            # Create a BeautifulSoup object\n",
    "            html = browser.html\n",
    "            soup_page = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "            links = soup_page.find_all(\"a\")\n",
    "            hrefs = [link.get(\"href\") for link in links]\n",
    "            box_scores = [link for link in hrefs if link and \"boxscore\" in link and \".html\" in link]\n",
    "            box_scores = [f\"https://www.basketball-reference.com{score}\" for score in box_scores]\n",
    "\n",
    "            base_cols = None\n",
    "            for box_score in box_scores:\n",
    "                browser.visit(box_score)\n",
    "                time.sleep(2)\n",
    "                \n",
    "                html=browser.html\n",
    "                soup_box = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "                score_table = soup_box.find('table', id='line_score')\n",
    "                tbody = score_table.find('tbody')\n",
    "                rows = tbody.find_all('tr')\n",
    "\n",
    "                line_score = []\n",
    "                for row in rows:\n",
    "                    # Get team name\n",
    "                    team = row.find('th', class_='center').text\n",
    "                    columns = row.find_all('td')\n",
    "\n",
    "                    # Create line score dictionary\n",
    "                    if(columns !=[]):\n",
    "                        total = columns[4].text\n",
    "\n",
    "                    # Create dictionary for dataframe later\n",
    "                    line_score_dict = { \"team\": team,\n",
    "                                        \"total\": total\n",
    "                    }\n",
    "\n",
    "                    # Add dictionary to array\n",
    "                    line_score.append(line_score_dict)\n",
    "\n",
    "                # Create Data frame\n",
    "                score_df = pd.DataFrame(line_score)\n",
    "                teams = [score[\"team\"] for score in line_score]\n",
    "\n",
    "                summaries = []\n",
    "                for team in teams:\n",
    "                    # Convert html table into pandas dataframe\n",
    "                    basic = pd.read_html(str(soup_box), attrs={\"id\": f\"box-{team}-game-basic\"}, index_col=0)[0]\n",
    "                    advanced = pd.read_html(str(soup_box), attrs={\"id\": f\"box-{team}-game-advanced\"}, index_col=0)[0]\n",
    "\n",
    "                    # Convert all columns with number to numeric for dataframes\n",
    "                    basic = basic.apply(pd.to_numeric, errors=\"coerce\")\n",
    "                    advanced = advanced.apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "                    # Remove the row that contains heards within the dataframe\n",
    "                    advanced = advanced.drop('Reserves')\n",
    "                    basic = basic.drop('Reserves')\n",
    "\n",
    "                    # Get headers for basic and advanced stats\n",
    "                    advanced_columns = []\n",
    "                    basic_columns = []\n",
    "                    for i in range(len(advanced.columns)):\n",
    "                        advanced_columns.append(advanced.columns[i][1])\n",
    "\n",
    "                    for i in range(len(basic.columns)):\n",
    "                        basic_columns.append(basic.columns[i][1])\n",
    "\n",
    "                    advanced.columns = advanced_columns\n",
    "                    basic.columns = basic_columns\n",
    "\n",
    "                    # Totals and Maxes\n",
    "                    totals = pd.concat([basic.iloc[-1, :], advanced.iloc[-1, :]])\n",
    "                    totals.index = totals.index.str.lower()\n",
    "\n",
    "                    maxes = pd.concat([basic.iloc[:-1, :].max(), advanced.iloc[:-1, :].max()])\n",
    "                    maxes.index = maxes.index.str.lower() + \"_max\"\n",
    "\n",
    "                    summary = pd.concat([totals, maxes])\n",
    "\n",
    "                    # Create common columns that are found for all teams\n",
    "                    if base_cols is None:\n",
    "                        base_cols = list(summary.index.drop_duplicates(keep=\"first\"))\n",
    "                        base_cols = [b for b in base_cols if \"bpm\" not in b]\n",
    "\n",
    "                    summary = summary[base_cols]\n",
    "                    summaries.append(summary)\n",
    "\n",
    "                summary = pd.concat(summaries, axis=1).T\n",
    "                game = pd.concat([summary, score_df], axis=1)\n",
    "                game[\"home\"] = [0, 1]\n",
    "\n",
    "                game_opp = game.iloc[::-1].reset_index()\n",
    "                game_opp.columns += \"_opp\"\n",
    "\n",
    "                # Merge both home and away team data together\n",
    "                full_game = pd.concat([game, game_opp], axis=1)\n",
    "\n",
    "                # Add the season the game was played in\n",
    "                full_game[\"season\"] = read_season_info(soup_box)\n",
    "\n",
    "                # Add date to dataframe\n",
    "                full_game[\"date\"] = box_score.split('/')[-1][:8]\n",
    "                full_game[\"date\"] = pd.to_datetime(full_game[\"date\"], format=\"%Y%m%d\")\n",
    "\n",
    "                # Specify who won the game\n",
    "                full_game[\"won\"] = full_game[\"total\"] > full_game[\"total_opp\"]\n",
    "\n",
    "                games.append(full_game)\n",
    "\n",
    "                if len(games) % 100 == 0:\n",
    "                    print(f\"{len(games)} / {len(box_scores)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8928eeae-6367-4f71-9d61-358f95a94b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "games_df = pd.concat(games, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d45a234-244b-4a36-a3bc-777ec44cd292",
   "metadata": {},
   "outputs": [],
   "source": [
    "games_df.to_csv(\"nba_games.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51b8a3d-7891-45b9-93eb-79017e2dfca4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a40e5e-33f3-438d-a8a1-6ef841f7f9ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
