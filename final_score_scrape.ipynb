{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8c86f2e-21b1-43c2-850f-ee9334957edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant libraries\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "import os\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b4b9556-79cc-4b5a-82db-5f430cf3c752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2018, 2019, 2020, 2021, 2022, 2023, 2024]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seasons = list(range(2018,2025))\n",
    "seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4f0e3967-173a-411e-af55-70d4735a1192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the browser\n",
    "executable_path = {'executable_path':\"C:\\Program Files (x86)\\msedgedriver.exe\"}\n",
    "browser = Browser('edge', **executable_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a1f60598-3ad4-4739-b321-c32a84e740d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_season_info(soup):\n",
    "    nav = soup.find('div', id='bottom_nav_container')\n",
    "    hrefs = [a[\"href\"] for a in nav.find_all(\"a\")]\n",
    "    season = hrefs[1].split()[0].split('_')[0].split('/')[-1]\n",
    "    return season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2fa55353-887a-4af9-9f5e-a04270f9155b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathering season 2017-2018 data\n",
      "100 / 104\n",
      "200 / 213\n",
      "300 / 213\n",
      "400 / 227\n",
      "500 / 227\n",
      "600 / 216\n",
      "700 / 216\n",
      "800 / 160\n",
      "900 / 160\n",
      "1000 / 222\n",
      "1100 / 222\n",
      "1200 / 136\n",
      "1300 / 31\n",
      "Gathering season 2018-2019 data\n",
      "1400 / 110\n",
      "1500 / 219\n",
      "1600 / 219\n",
      "1700 / 219\n",
      "1800 / 219\n",
      "1900 / 221\n",
      "2000 / 221\n",
      "2100 / 158\n",
      "2200 / 158\n",
      "2300 / 224\n",
      "2400 / 224\n",
      "2500 / 127\n",
      "2600 / 29\n",
      "Gathering season 2019-2020 data\n",
      "2700 / 215\n",
      "2800 / 215\n",
      "2900 / 220\n",
      "3000 / 220\n",
      "3100 / 220\n",
      "3200 / 222\n",
      "3300 / 222\n",
      "3400 / 168\n",
      "3500 / 168\n",
      "3600 / 123\n",
      "3700 / 123\n",
      "Gathering season 2020-2021 data\n",
      "3800 / 222\n"
     ]
    },
    {
     "ename": "TimeoutException",
     "evalue": "Message: timeout: Timed out receiving message from renderer: 299.746\n  (Session info: MicrosoftEdge=123.0.2420.97)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
      "Input \u001b[1;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     60\u001b[0m base_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m box_score \u001b[38;5;129;01min\u001b[39;00m box_scores:\n\u001b[1;32m---> 62\u001b[0m     \u001b[43mbrowser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbox_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     65\u001b[0m     html\u001b[38;5;241m=\u001b[39mbrowser\u001b[38;5;241m.\u001b[39mhtml\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\splinter\\driver\\webdriver\\__init__.py:319\u001b[0m, in \u001b[0;36mBaseWebDriver.visit\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvisit\u001b[39m(\u001b[38;5;28mself\u001b[39m, url):\n\u001b[1;32m--> 319\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:333\u001b[0m, in \u001b[0;36mWebDriver.get\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url):\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;124;03m    Loads a web page in the current browser session.\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 333\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:321\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    319\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 321\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    322\u001b[0m     response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(\n\u001b[0;32m    323\u001b[0m         response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:242\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)\n\u001b[1;32m--> 242\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mTimeoutException\u001b[0m: Message: timeout: Timed out receiving message from renderer: 299.746\n  (Session info: MicrosoftEdge=123.0.2420.97)\n"
     ]
    }
   ],
   "source": [
    "# Check to see if the page has loaded\n",
    "def page_loaded(browser):\n",
    "    return browser.is_element_present_by_id('line_score', wait_time=5)\n",
    "\n",
    "# Function to reload the page if it stalls for more than timeout seconds\n",
    "def reload_page(browser, url, timeout=7):\n",
    "    start_time = time.time()\n",
    "    while time.time() - start_time < timeout:\n",
    "        browser.visit(url)\n",
    "        if page_loaded(browser):\n",
    "            return True\n",
    "    return False\n",
    "            \n",
    "games = []\n",
    "\n",
    "for season in seasons:\n",
    "    # Visit the website for scraping\n",
    "    url = f\"https://www.basketball-reference.com/leagues/NBA_{season}_games.html\"\n",
    "    browser.visit(url)\n",
    "    time.sleep(2)\n",
    "    print(f'Gathering season {season - 1}-{season} data')\n",
    "    \n",
    "    # Check if the page has loaded\n",
    "    if not page_loaded(browser):\n",
    "        # If not, reload the page and wait\n",
    "        browser.reload()\n",
    "        time.sleep(3)\n",
    "\n",
    "    # Create a BeautifulSoup object\n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    table = soup.find('div', id='content')\n",
    "\n",
    "    if table is not None:\n",
    "        month_filter = table.find('div', class_='filter')\n",
    "        links = month_filter.find_all(\"a\")\n",
    "        hrefs = [link.get(\"href\") for link in links]\n",
    "        standing_pages = [f\"https://www.basketball-reference.com{link}\" for link in hrefs[:-1]]\n",
    "        \n",
    "        for page in standing_pages:\n",
    "            browser.visit(page)\n",
    "            time.sleep(2) \n",
    "            \n",
    "            # Create a BeautifulSoup object\n",
    "            html = browser.html\n",
    "            soup_page = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "            links = soup_page.find_all(\"a\")\n",
    "            hrefs = [link.get(\"href\") for link in links]\n",
    "            \n",
    "             # Filer out 2024 links\n",
    "            box_scores = [link for link in hrefs if link and \"boxscore\" in link and \".html\" in link and '2024' not in link]\n",
    "            box_scores = [f\"https://www.basketball-reference.com{score}\" for score in box_scores]\n",
    "            \n",
    "            \n",
    "            base_cols = None\n",
    "            for box_score in box_scores:\n",
    "                browser.visit(box_score)\n",
    "                time.sleep(2)\n",
    "                \n",
    "                html=browser.html\n",
    "                soup_box = BeautifulSoup(html, 'html.parser')\n",
    "                \n",
    "                score_table = soup_box.find('table', id='line_score')\n",
    "                \n",
    "                # # Cheack to see if score_table is None\n",
    "                # if score_table is None:\n",
    "                #     browser.reload()\n",
    "                #     time.sleep(2)\n",
    "                \n",
    "                if score_table is None or not page_loaded(browser):\n",
    "                    if not reload_page(browser, box_score, timeout=7):\n",
    "                        print(f\"Failed to reload {box_score}\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Re-create the BeautifulSoup object\n",
    "                    html=browser.html\n",
    "                    soup_box = BeautifulSoup(html, 'html.parser')\n",
    "                    score_table = soup_box.find('table', id='line_score')\n",
    "                \n",
    "                tbody = score_table.find('tbody')\n",
    "                rows = tbody.find_all('tr')\n",
    "\n",
    "                line_score = []\n",
    "                for row in rows:\n",
    "                    # Get team name\n",
    "                    team = row.find('th', class_='center').text\n",
    "                    columns = row.find_all('td')\n",
    "\n",
    "                    # Create line score dictionary\n",
    "                    if(columns !=[]):\n",
    "                        total = columns[4].text\n",
    "\n",
    "                    # Create dictionary for dataframe later\n",
    "                    line_score_dict = { \"team\": team,\n",
    "                                        \"total\": total\n",
    "                    }\n",
    "\n",
    "                    # Add dictionary to array\n",
    "                    line_score.append(line_score_dict)\n",
    "\n",
    "                # Create Data frame\n",
    "                score_df = pd.DataFrame(line_score)\n",
    "                teams = [score[\"team\"] for score in line_score]\n",
    "\n",
    "                summaries = []\n",
    "                for team in teams:\n",
    "                    # Convert html table into pandas dataframe\n",
    "                    basic = pd.read_html(str(soup_box), attrs={\"id\": f\"box-{team}-game-basic\"}, index_col=0)[0]\n",
    "                    advanced = pd.read_html(str(soup_box), attrs={\"id\": f\"box-{team}-game-advanced\"}, index_col=0)[0]\n",
    "\n",
    "                    # Convert all columns with number to numeric for dataframes\n",
    "                    basic = basic.apply(pd.to_numeric, errors=\"coerce\")\n",
    "                    advanced = advanced.apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "                    # Remove the row that contains heards within the dataframe\n",
    "                    advanced = advanced.drop('Reserves')\n",
    "                    basic = basic.drop('Reserves')\n",
    "\n",
    "                    # Get headers for basic and advanced stats\n",
    "                    advanced_columns = []\n",
    "                    basic_columns = []\n",
    "                    for i in range(len(advanced.columns)):\n",
    "                        advanced_columns.append(advanced.columns[i][1])\n",
    "\n",
    "                    for i in range(len(basic.columns)):\n",
    "                        basic_columns.append(basic.columns[i][1])\n",
    "\n",
    "                    advanced.columns = advanced_columns\n",
    "                    basic.columns = basic_columns\n",
    "\n",
    "                    # Totals and Maxes\n",
    "                    totals = pd.concat([basic.iloc[-1, :], advanced.iloc[-1, :]])\n",
    "                    totals.index = totals.index.str.lower()\n",
    "\n",
    "                    maxes = pd.concat([basic.iloc[:-1, :].max(), advanced.iloc[:-1, :].max()])\n",
    "                    maxes.index = maxes.index.str.lower() + \"_max\"\n",
    "\n",
    "                    summary = pd.concat([totals, maxes])\n",
    "\n",
    "                    # Create common columns that are found for all teams\n",
    "                    if base_cols is None:\n",
    "                        base_cols = list(summary.index.drop_duplicates(keep=\"first\"))\n",
    "                        base_cols = [b for b in base_cols if \"bpm\" not in b]\n",
    "\n",
    "                    summary = summary[base_cols]\n",
    "                    summaries.append(summary)\n",
    "\n",
    "                summary = pd.concat(summaries, axis=1).T\n",
    "                game = pd.concat([summary, score_df], axis=1)\n",
    "                game[\"home\"] = [0, 1]\n",
    "\n",
    "                game_opp = game.iloc[::-1].reset_index()\n",
    "                game_opp.columns += \"_opp\"\n",
    "\n",
    "                # Merge both home and away team data together\n",
    "                full_game = pd.concat([game, game_opp], axis=1)\n",
    "\n",
    "                # Add the season the game was played in\n",
    "                full_game[\"season\"] = read_season_info(soup_box)\n",
    "\n",
    "                # Add date to dataframe\n",
    "                full_game[\"date\"] = box_score.split('/')[-1][:8]\n",
    "                full_game[\"date\"] = pd.to_datetime(full_game[\"date\"], format=\"%Y%m%d\")\n",
    "\n",
    "                # Specify who won the game\n",
    "                full_game[\"won\"] = full_game[\"total\"] > full_game[\"total_opp\"]\n",
    "\n",
    "                games.append(full_game)\n",
    "\n",
    "                if len(games) % 100 == 0:\n",
    "                    print(f\"{len(games)} / {len(box_scores)}\")\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8928eeae-6367-4f71-9d61-358f95a94b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "games_df = pd.concat(games, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2d45a234-244b-4a36-a3bc-777ec44cd292",
   "metadata": {},
   "outputs": [],
   "source": [
    "games_df.to_csv(\"nba_games.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381cc7c4-1d43-4536-bc93-e077c049e5d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
