{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "f8c86f2e-21b1-43c2-850f-ee9334957edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant libraries\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "86441e7c-3fa9-41d1-aa2c-949b3ff6ce92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_DIR = \"data\"\n",
    "# STANDINGS_DIR = os.path.join(DATA_DIR, \"standings\")\n",
    "# SCORES_DIR = os.path.join(DATA_DIR, \"scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "9b4b9556-79cc-4b5a-82db-5f430cf3c752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2021]"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seasons = list(range(2021,2022))\n",
    "seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "4f0e3967-173a-411e-af55-70d4735a1192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the browser\n",
    "executable_path = {'executable_path':\"C:\\Program Files (x86)\\msedgedriver.exe\"}\n",
    "browser = Browser('edge', **executable_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "a1f60598-3ad4-4739-b321-c32a84e740d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_season_info(soup):\n",
    "    nav = soup.find('div', id='bottom_nav_container')\n",
    "    hrefs = [a[\"href\"] for a in nav.find_all(\"a\")]\n",
    "    season = hrefs[1].split()[0].split('_')[0].split('/')[-1]\n",
    "    return season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "eaf6ed24-4036-4c8e-9a23-0bf40e0e072f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for season in seasons:\n",
    "    # Visit the website for scraping\n",
    "    url = f\"https://www.basketball-reference.com/leagues/NBA_{season}_games.html\"\n",
    "    browser.visit(url)\n",
    "\n",
    "    # Create a BeautifulSoup object\n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    filter_div = soup.find('div', class_='filter')\n",
    "    links = filter_div.find_all('a')\n",
    "    urls = [link.get(\"href\") for link in links]\n",
    "    \n",
    "    html=browser.html\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    table = soup.find('table', id='schedule')\n",
    "\n",
    "    if table is not None:\n",
    "        links = table.find_all(\"a\")\n",
    "        hrefs = [link.get('href') for link in links]\n",
    "        box_scores = [link for link in hrefs if link and \"boxscore\" in link and \".html\" in link]\n",
    "        box_scores = [f\"https://www.basketball-reference.com{score}\" for score in box_scores]\n",
    "    else:\n",
    "        # If the table is not found, handle this case accordingly\n",
    "        print(\"Table with id 'schedule' not found.\")\n",
    "\n",
    "    base_cols = None\n",
    "    games = []\n",
    "\n",
    "    for box_score in box_scores:\n",
    "        browser.visit(box_score)\n",
    "        time.sleep(2)\n",
    "        html=browser.html\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        score_table = soup.find('table', id='line_score')\n",
    "        tbody = score_table.find('tbody')\n",
    "        rows = tbody.find_all('tr')\n",
    "\n",
    "        line_score = []\n",
    "\n",
    "        for row in rows:\n",
    "            # Get team name\n",
    "            team = row.find('th', class_='center').text\n",
    "            columns = row.find_all('td')\n",
    "\n",
    "            # Create line score dictionary\n",
    "            if(columns !=[]):\n",
    "                total = columns[4].text\n",
    "\n",
    "            # Create dictionary for dataframe later\n",
    "            line_score_dict = { \"team\": team,\n",
    "                                \"total\": total\n",
    "            }\n",
    "\n",
    "            # Add dictionary to array\n",
    "            line_score.append(line_score_dict)\n",
    "\n",
    "        # Create Data frame\n",
    "        score_df = pd.DataFrame(line_score)\n",
    "\n",
    "        teams = [score[\"team\"] for score in line_score]\n",
    "\n",
    "       \n",
    "        summaries = []\n",
    "        for team in teams:\n",
    "            # Convert html table into pandas dataframe\n",
    "            basic = pd.read_html(str(soup), attrs={\"id\": f\"box-{team}-game-basic\"}, index_col=0)[0]\n",
    "            advanced = pd.read_html(str(soup), attrs={\"id\": f\"box-{team}-game-advanced\"}, index_col=0)[0]\n",
    "            \n",
    "            # Convert all columns with number to numeric for dataframes\n",
    "            basic = basic.apply(pd.to_numeric, errors=\"coerce\")\n",
    "            advanced = advanced.apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "            # Remove the row that contains heards within the dataframe\n",
    "            advanced = advanced.drop('Reserves')\n",
    "            basic = basic.drop('Reserves')\n",
    "\n",
    "            # Get headers for basic and advanced stats\n",
    "            advanced_columns = []\n",
    "            basic_columns = []\n",
    "            for i in range(len(advanced.columns)):\n",
    "                advanced_columns.append(advanced.columns[i][1])\n",
    "\n",
    "            for i in range(len(basic.columns)):\n",
    "                basic_columns.append(basic.columns[i][1])\n",
    "\n",
    "            advanced.columns = advanced_columns\n",
    "            basic.columns = basic_columns\n",
    "\n",
    "            # Totals and Maxes\n",
    "            totals = pd.concat([basic.iloc[-1, :], advanced.iloc[-1, :]])\n",
    "            totals.index = totals.index.str.lower()\n",
    "\n",
    "            maxes = pd.concat([basic.iloc[:-1, :].max(), advanced.iloc[:-1, :].max()])\n",
    "            maxes.index = maxes.index.str.lower() + \"_max\"\n",
    "\n",
    "            summary = pd.concat([totals, maxes])\n",
    "            \n",
    "            # Create comon columns that are found for all teams\n",
    "            if base_cols is None:\n",
    "                base_cols = list(summary.index.drop_duplicates(keep=\"first\"))\n",
    "                base_cols = [b for b in base_cols if \"bpm\" not in b]\n",
    "\n",
    "            summary = summary[base_cols]\n",
    "            summaries.append(summary)\n",
    "\n",
    "        summary = pd.concat(summaries, axis=1).T\n",
    "        game = pd.concat([summary, score_df], axis=1)\n",
    "        game[\"home\"] = [0, 1]\n",
    "\n",
    "        game_opp = game.iloc[::-1].reset_index()\n",
    "        game_opp.columns += \"_opp\"\n",
    "\n",
    "        # Merge both hame and away team data together\n",
    "        full_game = pd.concat([game, game_opp], axis=1)\n",
    "\n",
    "        # Add the season the game was played in\n",
    "        full_game[\"season\"] = read_season_info(soup)\n",
    "\n",
    "        # Add date to dataframe\n",
    "        full_game[\"date\"] = box_score.split('/')[-1][:8]\n",
    "        full_game[\"date\"] = pd.to_datetime(full_game[\"date\"], format=\"%Y%m%d\")\n",
    "\n",
    "        # Specify who won the game\n",
    "        full_game[\"won\"] = full_game[\"total\"] > full_game[\"total_opp\"]\n",
    "\n",
    "        games.append(full_game)\n",
    "\n",
    "        if len(games) % 100 == 0:\n",
    "            print(f\"{len(games)} / {len(box_scores)}\")\n",
    "        \n",
    "        time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "8928eeae-6367-4f71-9d61-358f95a94b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "games_df = pd.concat(games, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "2d45a234-244b-4a36-a3bc-777ec44cd292",
   "metadata": {},
   "outputs": [],
   "source": [
    "games_df.to_csv(\"nba_games.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51b8a3d-7891-45b9-93eb-79017e2dfca4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a40e5e-33f3-438d-a8a1-6ef841f7f9ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
